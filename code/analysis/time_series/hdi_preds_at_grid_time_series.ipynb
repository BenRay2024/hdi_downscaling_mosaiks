{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6756f538",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "repo_dir = os.environ.get(\"REPO_DIR\")\n",
    "code_dir = os.path.join(repo_dir, \"code/\")\n",
    "data_dir = os.path.join(repo_dir, \"data/\")\n",
    "\n",
    "os.chdir(code_dir)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import scipy.linalg\n",
    "import pickle\n",
    "import sklearn \n",
    "import sys\n",
    "import pandas as pd\n",
    "from importlib import reload\n",
    "\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.linear_model import Ridge\n",
    "import seaborn as sns\n",
    "\n",
    "from scipy.stats import spearmanr, mode\n",
    "\n",
    "import geopandas as gpd\n",
    "import rasterio\n",
    "import zarr\n",
    "\n",
    "import gc\n",
    "\n",
    "import warnings\n",
    "\n",
    "from mosaiks.utils.imports import *\n",
    "\n",
    "from mosaiks.utils.io import weighted_groupby\n",
    "from affine import Affine\n",
    "\n",
    "import cartopy.crs as ccrs\n",
    "# Key prediction functions are here\n",
    "from analysis.prediction_utils import (flatten_raster,rasterize_df)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3beb5a86",
   "metadata": {},
   "source": [
    "# Predicting grid level HDI\n",
    "\n",
    "In this notebook, we recenter HDI at the grid level for a time series from 2012 to 2021. We use an intermediate out from the notebook `hdi_preds_at_grid_time_series.ipynb`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "614dd3da",
   "metadata": {},
   "outputs": [],
   "source": [
    "task = \"Sub-national HDI\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d3f53f68",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_pickle(data_dir + \"preds/raw_hdi_preds_at_grid_with_hsdl.p\").reset_index()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "39a8a80f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Drop preds that do not have 0 population in the HSDL dataset\n",
    "data = data[data[\"pop_binary\"] == 1].copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "f1f7ca92",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Assign smallest positive pop density weight to remaining locations where pop density weights were NaN\n",
    "data.loc[data[\"population\"].isnull(), \"population\"] = data[\"population\"].min()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "1656c2aa",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>index</th>\n",
       "      <th>lon</th>\n",
       "      <th>lat</th>\n",
       "      <th>GDLCODE</th>\n",
       "      <th>iso_code</th>\n",
       "      <th>constant</th>\n",
       "      <th>nl</th>\n",
       "      <th>population</th>\n",
       "      <th>raw_pred_hdi</th>\n",
       "      <th>raw_pred_hdi_not_clipped</th>\n",
       "      <th>Sub-national HDI</th>\n",
       "      <th>pop_binary</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>43.435</td>\n",
       "      <td>-22.905</td>\n",
       "      <td>MDGr117</td>\n",
       "      <td>MDG</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37.789421</td>\n",
       "      <td>-0.001531</td>\n",
       "      <td>-0.001531</td>\n",
       "      <td>0.408</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>43.435</td>\n",
       "      <td>-22.895</td>\n",
       "      <td>MDGr117</td>\n",
       "      <td>MDG</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37.789421</td>\n",
       "      <td>0.029665</td>\n",
       "      <td>0.029665</td>\n",
       "      <td>0.408</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>43.435</td>\n",
       "      <td>-22.885</td>\n",
       "      <td>MDGr117</td>\n",
       "      <td>MDG</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37.789425</td>\n",
       "      <td>0.028874</td>\n",
       "      <td>0.028874</td>\n",
       "      <td>0.408</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>43.435</td>\n",
       "      <td>-22.875</td>\n",
       "      <td>MDGr117</td>\n",
       "      <td>MDG</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>37.789421</td>\n",
       "      <td>0.021557</td>\n",
       "      <td>0.021557</td>\n",
       "      <td>0.408</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>94</th>\n",
       "      <td>94</td>\n",
       "      <td>43.435</td>\n",
       "      <td>-21.975</td>\n",
       "      <td>MDGr117</td>\n",
       "      <td>MDG</td>\n",
       "      <td>1</td>\n",
       "      <td>0.0</td>\n",
       "      <td>8.582693</td>\n",
       "      <td>0.050563</td>\n",
       "      <td>0.050563</td>\n",
       "      <td>0.408</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "    index     lon     lat  GDLCODE iso_code  constant   nl  population  \\\n",
       "1       1  43.435 -22.905  MDGr117      MDG         1  0.0   37.789421   \n",
       "2       2  43.435 -22.895  MDGr117      MDG         1  0.0   37.789421   \n",
       "3       3  43.435 -22.885  MDGr117      MDG         1  0.0   37.789425   \n",
       "4       4  43.435 -22.875  MDGr117      MDG         1  0.0   37.789421   \n",
       "94     94  43.435 -21.975  MDGr117      MDG         1  0.0    8.582693   \n",
       "\n",
       "    raw_pred_hdi  raw_pred_hdi_not_clipped  Sub-national HDI  pop_binary  \n",
       "1      -0.001531                 -0.001531             0.408           1  \n",
       "2       0.029665                  0.029665             0.408           1  \n",
       "3       0.028874                  0.028874             0.408           1  \n",
       "4       0.021557                  0.021557             0.408           1  \n",
       "94      0.050563                  0.050563             0.408           1  "
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.drop(columns =[\"lon01\",\"lat01\"], inplace=True)\n",
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "cf7594b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.drop(columns = task)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b0fcc6f0",
   "metadata": {},
   "source": [
    "## Merge with time series of GDL data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "98b3b90e",
   "metadata": {},
   "outputs": [],
   "source": [
    "t_df = pd.read_csv(data_dir + \"raw/GDL_HDI/SHDI-SGDI-Total 7.0.csv\",low_memory=False)\n",
    "t_df = t_df.rename(columns = {\"shdi\":task})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e60977a",
   "metadata": {},
   "source": [
    "## Re-center preds on the known ADM1 Value"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "3a7f558a",
   "metadata": {},
   "outputs": [],
   "source": [
    "grouped = io.weighted_groupby(data, \"GDLCODE\", weights_col_name=\"population\", cols_to_agg=[\"raw_pred_hdi\"] )\n",
    "grouped.rename(columns = {\"raw_pred_hdi\":\"weighted_avg_raw\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b79355b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = data.merge(grouped, left_on=\"GDLCODE\", right_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "d58a3889",
   "metadata": {},
   "outputs": [],
   "source": [
    "data[\"lat10\"] = np.round(np.round(data[\"lat\"] + .05,1) - .05,2)\n",
    "data[\"lon10\"] = np.round(np.round(data[\"lon\"] + .05,1) - .05,2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "8cafcd04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2012\n",
      "2013\n",
      "2014\n",
      "2015\n",
      "2016\n",
      "2017\n",
      "2018\n",
      "2019\n",
      "2020\n",
      "2021\n"
     ]
    }
   ],
   "source": [
    "year_range = np.arange(2012,2022)\n",
    "\n",
    "for year in year_range:\n",
    "    print(year)\n",
    "    \n",
    "    t_df_year = t_df[t_df[\"year\"] == year]\n",
    "    t_df_year = t_df_year.set_index(\"GDLCODE\")\n",
    "    \n",
    "    data_year = data.merge(t_df_year[[task]], \"left\", left_on=\"GDLCODE\",right_index=True)\n",
    "    \n",
    "    data_year[\"Sub-national HDI\"] = data_year[\"Sub-national HDI\"].astype(float)\n",
    "    data_year[\"adj_factor\"] = data_year[\"Sub-national HDI\"] - data_year[\"weighted_avg_raw\"]\n",
    "    data_year[\"centered_pred\"] = data_year[\"raw_pred_hdi\"] + data_year[\"adj_factor\"]\n",
    "    \n",
    "    \n",
    "    ## Rasterize and upsample\n",
    "    pre_raster = data_year.groupby([\"lon10\",\"lat10\"])[[\"centered_pred\",\"population\",\"Sub-national HDI\",\"GDLCODE\"]].agg(\n",
    "    {\n",
    "    \"population\": np.nansum, # Sum the weights\n",
    "    \"Sub-national HDI\": lambda x: mode(x, nan_policy=\"omit\")[0], # For this col, keep the modal HDI\n",
    "     \"GDLCODE\": lambda x: mode(x,nan_policy=\"omit\")[0], # For this col, keep the modal parent ADM1 code\n",
    "    }) #ignore NaNs for all\n",
    "    \n",
    "    \n",
    "    #### Now for HDI we want to take the weighted average of the cells, \n",
    "    # using the same GPW pop density weights that we have been using throughout\n",
    "    pre_raster = pd.concat( [pre_raster,weighted_groupby(data_year, \n",
    "                                                       [\"lon10\",\"lat10\"], \n",
    "                                                       \"population\", \n",
    "                                                       cols_to_agg = [\"centered_pred\"]\n",
    "                                                      )\n",
    "                           ],axis=1).reset_index()\n",
    "    \n",
    "    pre_raster[\"clipped\"] = np.clip(pre_raster[\"centered_pred\"],0,1)\n",
    "    \n",
    "    pre_raster = pre_raster.reset_index()\n",
    "    \n",
    "#     pre_raster.to_pickle(data_dir + \"preds/time_series/\"\n",
    "#            f\"hdi_grid_predictions_flat_file_{year}.p\")\n",
    "\n",
    "    raster, extent = rasterize_df(pre_raster, \n",
    "                              data_colname = \"clipped\", \n",
    "                              grid_delta=.1, \n",
    "                              lon_col=\"lon10\", \n",
    "                              lat_col=\"lat10\",\n",
    "                             custom_extent = (-180,180,-56,74)\n",
    "                             )\n",
    "    \n",
    "    ####  Write grid data product as a raster\n",
    "    \n",
    "    meta = {'driver': 'GTiff',\n",
    " 'dtype': 'float64',\n",
    " 'nodata': np.nan,\n",
    " 'width': 3600,\n",
    " 'height': 1300,\n",
    " 'count': 1,\n",
    "'crs': \"EPSG:4326\",\n",
    "'transform': Affine(0.1, 0.0, extent[0],\n",
    "        0.0, -0.1, extent[3])\n",
    "       }\n",
    "\n",
    "    raster_outpath = (data_dir + \"preds/time_series\"\n",
    "               f\"hdi_raster_predictions_{year}.tif\")\n",
    "\n",
    "    with rasterio.open(raster_outpath , \"w\", **meta) as dest:\n",
    "         dest.write(np.array([raster]))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b9a5cf12",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.15"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
